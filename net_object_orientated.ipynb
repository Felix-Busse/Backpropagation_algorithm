{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27606938",
   "metadata": {},
   "source": [
    "# Lecture 2\n",
    "### Programming neuronal network object orientated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d3e76b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72692415",
   "metadata": {},
   "outputs": [],
   "source": [
    "class net:\n",
    "    ''' class to hold a neuronal net. \n",
    "    It is not intended that number of layers and/or neurons changes in object of this class.\n",
    "    Parameter neurons defines number of neurons in each layer (incl. input and output layer). \n",
    "    Parameter neurons should be passed as list object of integers.\n",
    "    Parameter activations holds activations for each layer, needs to be list object with one\n",
    "    element less than neurons. Activations are strings: 'linear', 'jump', 'ReLU', 'sigmoid'.\n",
    "    Variables y_layers and df_layers are intended to hold status (value and derivative f'(z)) \n",
    "    of all neurons for backprop'''\n",
    "    def __init__(self, neurons, activations):\n",
    "        # Checking if net is well defined\n",
    "        if (len(neurons) - 1) != len(activations): \n",
    "            # throw error, if net is bad defiend. TO BE IMPLEMENTED\n",
    "            raise ValueError('Number of activations mismatches number of layers')\n",
    "        # Creating biases vectors as a list of 1D numpy arrays\n",
    "        # Creating weights matrices as a list of 2D numpy arrays\n",
    "        self.b = []\n",
    "        self.w = []\n",
    "        # Creating matrices to store gradient of biasas as a list of 1D numpy arrays\n",
    "        self.db = []\n",
    "        # Creating matrices to store gradient of weights as a list of 2D numpy arrays\n",
    "        self.dw = []\n",
    "        for i, n_layer in enumerate(neurons[1:]):\n",
    "            n_previous_layer = neurons[i] # i runs from 0 to len(neurons) - 1\n",
    "            # Creating biases with arbitary values uniformly distributed from -1 to 1\n",
    "            self.b.append(np.random.uniform(low=-1, high=1, size=(n_layer)))\n",
    "            # Creating corresponding list of 1D arrays to store gradient of biases\n",
    "            self.db.append(np.zeros(shape=n_layer))\n",
    "            # Creating weights with arbitary values uniformly distributed from -1 to 1\n",
    "            # Transposed to match matrix multiplication y @ w later (this is for handling \n",
    "            # batches of input data simultaniously)\n",
    "            self.w.append((np.random.uniform(low=-1, high=1, size=(n_layer, n_previous_layer))).T)\n",
    "            # Initializing corresponding list of matrices intended to hold gradients dw of weights w\n",
    "            self.dw.append(np.zeros(shape=(n_layer, n_previous_layer)))\n",
    "        # Defining activations\n",
    "        self.a = activations\n",
    "        # Defining list of empty lists as storage for values y=f(z) of neurons, as well as derivative\n",
    "        # f'(z) of neurons.\n",
    "        self.y_layers = [[] for i in range(len(neurons))] # as many entrys in y_layers as layers of nerons\n",
    "        self.df_layers = [[] for i in range(len(neurons))] # one less entrys in df_layers as layers in net,\n",
    "                                                              # because input layer's derivative is undefined.\n",
    "                                                              # However index is chosen same as for y_layer, to\n",
    "                                                              # avoid index shift between these. Position \n",
    "                                                              # df_layers[0] will stay unused\n",
    "    \n",
    "#    def apply_factor_to_weights(self, factor):\n",
    "#        ''' Gives possibilty to factorize initial weights'''\n",
    "#        self.w = [factor*x for x in self.w]\n",
    "        \n",
    "    def apply_factor_to_weights(self, factor):\n",
    "        ''' Gives possibilty to factorize initial weights'''\n",
    "        for i, value in enumerate(self.w):\n",
    "            self.w[i] *= factor\n",
    "  \n",
    "    def apply_factor_to_biases(self, factor):\n",
    "        for i, value in enumerate(self.b):\n",
    "            self.b[i] *= factor\n",
    "        \n",
    "    def __net_f_df__(self, z, activation):\n",
    "        '''Returns value for activation of f(z) and its derivative f'(z)\n",
    "        '''\n",
    "        if activation == 'sigmoid':\n",
    "            return([1/(1+np.exp(-z)), \n",
    "                1/((1+np.exp(-z))*(1+np.exp(z)))])\n",
    "        elif activation == 'jump': # cheating a bit here: replacing f'(z)=delta(z) by something smooth\n",
    "            return([np.array(z>0,dtype='float'), \n",
    "                10.0/((1+np.exp(-10*z))*(1+np.exp(10*z))) ] )\n",
    "        elif activation == 'ReLU':\n",
    "            return([(z>0)*z, (z>0)*1.0])\n",
    "        elif activation == 'linear':\n",
    "            return([z, np.ones(shape=z.shape)])\n",
    "    \n",
    "    def __apply_forward_step__(self, y_in, n):\n",
    "        ''' Performs forward calculation step from one layer to next.\n",
    "        n is index of calculated layer'''\n",
    "        z = (y_in @ self.w[n-1]) + self.b[n-1]\n",
    "        return(self.__net_f_df__(z, self.a[n-1]))\n",
    "    \n",
    "    def apply_net(self, y_in):\n",
    "        '''One forwards loop through the net, returning output neuron's values.\n",
    "        y_in must provide input neuron's values. Keeping values necessary for backprop '''\n",
    "        self.y_layers[0] = y_in.copy() # copy, to exclude interference of class with source of input\n",
    "        for i in range(len(self.w)):\n",
    "            self.y_layers[i+1], self.df_layers[i+1] = self.__apply_forward_step__(self.y_layers[i], i+1)\n",
    "        return(self.y_layers[-1]) # Returning last element of y gives output layer values to caller\n",
    "    \n",
    "    def apply_net_simple(self, y_in):\n",
    "        '''Simple forward loop trough net to obtain output. Without keeping values for backprop.'''\n",
    "        y = y_in.copy() # Copy of input neurons values, to not interfere with caller\n",
    "        for i in range(len(self.w)):\n",
    "            y = self. __apply_forward_step__(y, i+1)[0] # Keep only y-values, dumping derivitave f'(z)\n",
    "        return(y) # Returning output neuron's values\n",
    "    \n",
    "    def __backprop_step__(self, delta, n):\n",
    "        '''Takes delta-vector of layer n and returns delta-vector vor layer n-1. Index of layer \"n\" must\n",
    "        explicitly passed'''\n",
    "        return delta @ (self.w[n].T) * self.df_layers[n]\n",
    "    \n",
    "    def __backprop__(self, y_target):\n",
    "        ''' Performs backpropagation of net with given batch of target values. Adjustes weights and biases'''\n",
    "        # Calculating batchsize for averaging\n",
    "        batchsize = y_target.shape[0]\n",
    "        # Calculating first vector delta from value of output neurons compared with target values and f'(z) \n",
    "        # of output layer\n",
    "        delta = (self.y_layers[-1] - y_target) * self.df_layers[-1]\n",
    "        # Calculating gradients of cost function from delta vector\n",
    "        self.dw[-1] = self.y_layers[-2].T @ delta / batchsize # Averaging over samples in batch necessary. Trans-\n",
    "        # pose of y_layers necessary, so matrix product sums over neurons not batchsize\n",
    "        self.db[-1] = delta.sum(0) / batchsize # Averaging over samples in batch necessary\n",
    "        # Loop to calculate gradient of all remaining weight matrices\n",
    "        for i in reversed(range(len(self.y_layers)-2)):\n",
    "            # calculate updated delta (one step backwards into net)\n",
    "            delta = self.__backprop_step__(delta, i+1) #delta = delta @ (self.w[i] * self.df_layers[i])\n",
    "            # From delta calculate gradient of weights and average over batchsize\n",
    "            self.dw[i] = ((self.y_layers[i].T) @ delta) / batchsize\n",
    "            # From delta calculate gradients of biases and average over batchsize\n",
    "            self.db[i] = delta.sum(0) / batchsize\n",
    "            \n",
    "    def __gradient_step__(self, eta):\n",
    "        # Updating weights by substracting gradient dw times learning rate eta\n",
    "        for i in range(len(self.w)):\n",
    "            self.w[i] -= eta * self.dw[i]\n",
    "        # Updating biases by substracting gradient db times learning rate eta\n",
    "        for i in range(len(self.b)):\n",
    "            self.b[i] -= eta * self.db[i]\n",
    "            \n",
    "    def train_net(self, y_in, y_target, eta):\n",
    "        if len(y_target.shape) == 1:\n",
    "            y_target = y_target[:, np.newaxis]\n",
    "        # Apply net to obtain output as of current state of net\n",
    "        y_out = self.apply_net(y_in)\n",
    "        # Perform backpropagation algorithm to obtain gradients for weights and biases\n",
    "        self.__backprop__(y_target)\n",
    "        # Calculate new weights and biases from result of backpropagation\n",
    "        self.__gradient_step__(eta)\n",
    "        # Return cost function\n",
    "        return(0.5*((y_out - y_target)**2).sum() / y_in.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc8ba26",
   "metadata": {},
   "source": [
    "## Demonstrating learning capability of programmed class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27dca8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.13681951,  0.03628172, -0.44632999,  2.90835398])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = net(neurons=[2, 5, 4, 1], activations=['ReLU', 'ReLU', 'ReLU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb5f08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    a.train_net(y_in=np.array([[-2, 1]]), y_target=np.array([5]), eta=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67687957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.apply_net_simple(y_in=np.array([[-2, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "467a55d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = net(neurons=[2, 10, 10, 1], activations=['sigmoid', 'ReLU', 'linear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "343d1ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    c.train_net(y_in=np.array([[-2, 1], [-1, 3], [4, 4]]), y_target=np.array([1, -1, -1.5]), eta=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0587528a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82112369],\n",
       "       [-0.67718875],\n",
       "       [-1.66223731]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.y_layers[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c87a03",
   "metadata": {},
   "source": [
    "## Learning an simple image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75c47fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f449c62fb50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining image as binary mask\n",
    "target = np.diag(v=np.array([1, 1, 1, 1, 1, 1, 1]))\n",
    "for i in range(target.shape[1]):\n",
    "    target[target.shape[1] - i - 1, i] = 1\n",
    "plt.imshow(target, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83d868c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining neuronal network\n",
    "image_net = net(neurons=[2, 75, 75, 75, 1], activations=['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "54b59074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006903425266766255\n"
     ]
    }
   ],
   "source": [
    "# Multible application of stochastic gradient descent\n",
    "for i in range(5000 - 1):\n",
    "    # Extracting samples from target image\n",
    "    batchsize = 15\n",
    "    samples = np.zeros(shape=(batchsize, 3))\n",
    "    # Taking arbitary values from traget-image to set up traing batch\n",
    "    for i in range(batchsize):\n",
    "        coord1 = np.random.randint(low=0, high=target.shape[0])\n",
    "        coord2 = np.random.randint(low=0, high=target.shape[1])\n",
    "        samples[i, 0] = coord1\n",
    "        samples[i, 1] = coord2\n",
    "        samples[i, 2] = target[coord1, coord2]\n",
    "\n",
    "    # Learning one cycle on sample\n",
    "    image_net.train_net(y_in=samples[:, :-1], y_target=samples[:, 2].flatten(), eta=0.01)\n",
    "# Printing last value of cost function to screen\n",
    "print(image_net.train_net(y_in=samples[:, :-1], y_target=samples[:, 2].flatten(), eta=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ceda882e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4498a8f430>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot resulting image of net after learning\n",
    "\n",
    "axes = (np.ogrid[0:target.shape[1], 0:target.shape[0]])\n",
    "grid = np.meshgrid(axes[0], axes[1])\n",
    "image_index = np.concatenate([grid[1].flatten()[:, np.newaxis], grid[0].flatten()[:, np.newaxis]], axis=1)\n",
    "image_learned = image_net.apply_net_simple(y_in=image_index)\n",
    "plt.imshow(image_learned.reshape(target.shape), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c40bc",
   "metadata": {},
   "source": [
    "## Performing some statistics on weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c8dd3a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0268238034361166"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_net.w[0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fec877e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08939795327656536"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_net.w[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "52b7e512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5749095365833058"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_net.b[2].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d733687c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.022042619801323656"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_net.b[2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b0dee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
